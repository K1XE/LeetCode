<div align="center">
  <h1 style="margin-bottom: 0;">刷题记录</h1>
  <p>
    📚<a href="https://leetcode.cn/studyplan/top-100-liked/" target="_blank">HOT100</a> | 
    📚<a href="https://programmercarl.com/" target="_blank">代码随想录</a> |
    📚<a href="https://leetcode.cn/studyplan/top-interview-150/" target="_blank">top-interview-150</a>
  </p>
  <p>
    📚<a href="https://hwcoder.top/Manual-Coding-1" target="_blank">Large Language Model Algorithm</a>
  </p>
</div>

<div align="center">

### 📝 [LeetCode 刷题进度](https://leetcode.cn/)

| 难度 | 已完成题数 |
| :--: | :--------: |
| 简单 |    139    |
| 中等 |    306    |
| 困难 |     72     |

---


### 📝 [LLM 手撕经典算法 打卡记录](https://hwcoder.top/Manual-Coding-1)

| 序号 | 篇章                                                      | 算法                                                                                                 |
| ---- | ------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- |
| 1    | Attention            | <ul><li>✔️ Scaled Dot-Product Attention</li><li>✔️ Multi-Head Attention (MHA)</li><li>✔️ Multi-Query Attention (MQA)</li><li>✔️ Grouped Query Attention (GQA)</li><li>⬜ Multi-head Latent Attention (MLA)</li></ul> |
| 2    | nn             | <ul><li>✔️ Layer Normalization (LN)</li><li>✔️ RMSNorm</li><li>✔️ Batch Normalization (BN)</li><li>✔️ Dropout</li><li>✔️ Backpropagation</li><li>✔️ Gradient Accumulation</li></ul> |
| 3    | Transformer          | <ul><li>✔️ Token Embedding</li><li>✔️ Positional Embedding</li><li>✔️ RoPE</li><li>✔️ Encoder Layer (MHA + FFN)</li><li>✔️ Decoder Layer</li><li>✔️ Stacked Encoder/Decoder</li><li>✔️ Transformer</li></ul> |
| 4    | Function             | <ul><li>✔️ MSE</li><li>✔️ CE, BCE, KL, Focal</li><li>✔️ Sigmoid, Tanh</li><li>✔️ ReLU, Leaky ReLU, ELU</li><li>✔️ Swish, GeLU, SwiGLU</li><li>✔️ Softmax</li><li>✔️ PPL, ROUGE, BLEU</li></ul> |
| 5    | ML            | <ul><li>✔️ 线性回归</li><li>✔️ 逻辑回归</li><li>✔️ Softmax 回归</li><li>⬜ 反向传播</li><li>⬜ SGD 优化器</li></ul> |
| 6    | RLHF                 | <ul><li>✔️ 广义优势估计 (GAE)</li><li>✔️ PPO Loss & Value Loss</li><li>✔️ DPO Loss</li><li>⬜ GRPO Loss</li><li>✔️ 无偏 KL 散度</li><li>✔️ 三种 KL 散度估计器</li></ul> |