<div align="center">
  <h1 style="margin-bottom: 0;">刷题记录</h1>
  <p>
    📚<a href="https://leetcode.cn/studyplan/top-100-liked/" target="_blank">HOT100</a> | 
    📚<a href="https://programmercarl.com/" target="_blank">代码随想录</a> |
    📚<a href="https://leetcode.cn/studyplan/top-interview-150/" target="_blank">top-interview-150</a>
  </p>
  <p>
    📚<a href="https://hwcoder.top/Manual-Coding-1" target="_blank">Large Language Model Algorithm</a>
  </p>
</div>

<div align="center">

### 📝 [LeetCode 刷题进度](https://hwcoder.top/Manual-Coding-1)

| 难度 | 已完成题数 |
| :--: | :--------: |
| 简单 |    116    |
| 中等 |    237    |
| 困难 |     53     |

---

### 📝 [LLM 手撕经典算法 打卡记录](https://hwcoder.top/Manual-Coding-1)

| 序号 | 篇章名称                                                      | 算法打卡                                                                                                 |
| ---- | ------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- |
| 1    | [Attention 篇](https://hwcoder.top/Manual-Coding-1)            | <ul><li>✔️ Scaled Dot-Product Attention</li><li>✔️ Multi-Head Attention (MHA)</li><li>✔️ Multi-Query Attention (MQA)</li><li>✔️ Grouped Query Attention (GQA)</li><li>⬜ Multi-head Latent Attention (MLA)</li></ul> |
| 2    | [神经网络 篇](https://hwcoder.top/Manual-Coding-2)             | <ul><li>✔️ Layer Normalization (LN)</li><li>✔️ RMSNorm</li><li>✔️ Batch Normalization (BN)</li><li>⬜ Dropout</li></ul> |
| 3    | [Transformer 篇](https://hwcoder.top/Manual-Coding-3)          | <ul><li>⬜ Token Embedding</li><li>⬜ Positional Embedding</li><li>⬜ Encoder Layer (MHA + FFN)</li><li>⬜ Decoder Layer</li><li>⬜ Stacked Encoder/Decoder</li><li>⬜ 完整 Transformer</li></ul> |
| 4    | [经典函数 篇](https://hwcoder.top/Manual-Coding-4)             | <ul><li>⬜ 损失函数：MSE</li><li>⬜ 损失函数：CE, BCE, KL, Focal</li><li>⬜ 激活函数：Sigmoid, Tanh</li><li>⬜ 激活函数：ReLU, Leaky ReLU, ELU</li><li>⬜ 激活函数：Swish, GeLU, SwiGLU</li><li>⬜ 激活函数：Softmax</li><li>⬜ 指标：PPL, ROUGE, BLEU</li></ul> |
| 5    | [机器学习 篇](https://hwcoder.top/Manual-Coding-5)             | <ul><li>⬜ 线性回归</li><li>⬜ 逻辑回归</li><li>⬜ Softmax 回归</li><li>⬜ 反向传播</li><li>⬜ SGD 优化器</li></ul> |
| 6    | [RLHF 篇](https://hwcoder.top/Manual-Coding-6)                 | <ul><li>⬜ 广义优势估计 (GAE)</li><li>⬜ PPO Loss & Value Loss</li><li>⬜ DPO Loss</li><li>⬜ GRPO Loss</li><li>⬜ 无偏 KL 散度</li></ul> |
